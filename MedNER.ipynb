{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOv37LOsdI0QLIuI/0WU6tZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lhua0420/MedNER/blob/main/MedNER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 导入必要的 Python 库\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.metrics import classification_report\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "\n",
        "# 确保每次实验结果一致\n",
        "torch.manual_seed(1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rsL4KHx9RBIg",
        "outputId": "e2aba6f7-2711-413a-9875-23aabe7c74cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d2cb01a9750>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(file_path):\n",
        "    \"\"\"\n",
        "    读取并解析数据文件，返回句子列表。\n",
        "    每个句子是字符和标签的元组列表。\n",
        "    \"\"\"\n",
        "    with open(file_path, 'r', encoding='utf-8') as file:\n",
        "        lines = file.readlines()\n",
        "        sentences = []\n",
        "        sentence = []\n",
        "        for line in lines:\n",
        "            if line.strip() == '':\n",
        "                if sentence:\n",
        "                    sentences.append(sentence)\n",
        "                    sentence = []\n",
        "            else:\n",
        "                char, label = line.strip().split()\n",
        "                sentence.append((char, label))\n",
        "\n",
        "        # 检查并添加最后一个句子（如果非空）\n",
        "        if sentence:\n",
        "            sentences.append(sentence)\n",
        "\n",
        "    # 打印读取的句子数量和前几个句子的示例\n",
        "    print(f\"Total sentences read: {len(sentences)}\")\n",
        "    print(\"Example sentences:\")\n",
        "    for i in range(min(3, len(sentences))):\n",
        "        print(sentences[i])\n",
        "\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def build_vocab(sentences):\n",
        "    \"\"\"\n",
        "    从句子中构建字符和标签的词汇表。\n",
        "    返回字符和标签的 Counter 对象。\n",
        "    \"\"\"\n",
        "    chars = [[char for char, label in sentence] for sentence in sentences]\n",
        "    labels = [[label for char, label in sentence] for sentence in sentences]\n",
        "    vocab = Counter(chain(*chars))\n",
        "    tagset = Counter(chain(*labels))\n",
        "\n",
        "    # 打印词汇表和标签集的大小\n",
        "    print(f\"Vocabulary size: {len(vocab)}\")\n",
        "    print(f\"Tag set size: {len(tagset)}\")\n",
        "\n",
        "    return vocab, tagset\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    \"\"\"\n",
        "    自定义 collate 函数，用于 DataLoader 中动态填充序列。\n",
        "    \"\"\"\n",
        "    chars, labels = zip(*batch)\n",
        "    chars_padded = pad_sequence(chars, batch_first=True, padding_value=0)\n",
        "    labels_padded = pad_sequence(labels, batch_first=True, padding_value=label2idx['O'])\n",
        "\n",
        "    # 打印批处理的大小和填充后的序列尺寸\n",
        "    # print(f\"Batch size: {len(batch)}\")\n",
        "    # print(f\"Padded chars size: {chars_padded.size()}\")\n",
        "    # print(f\"Padded labels size: {labels_padded.size()}\")\n",
        "\n",
        "    return chars_padded, labels_padded\n",
        "\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"\n",
        "    自定义数据集类，用于处理 NER 数据。\n",
        "    将句子转换为字符索引和标签索引的形式。\n",
        "    \"\"\"\n",
        "    def __init__(self, sentences, char2idx, label2idx):\n",
        "        self.sentences = sentences\n",
        "        self.char2idx = char2idx\n",
        "        self.label2idx = label2idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sentences)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sentence, labels = zip(*self.sentences[index])\n",
        "        char_indices = [self.char2idx.get(char, self.char2idx['<UNK>']) for char in sentence]\n",
        "        label_indices = [self.label2idx[label] for label in labels]\n",
        "\n",
        "        # 打印正在处理的句子索引和内容（可选）\n",
        "        # print(f\"Processing sentence index: {index}\")\n",
        "        # print(f\"Sentence: {sentence}\")\n",
        "\n",
        "        return torch.tensor(char_indices, dtype=torch.long), torch.tensor(label_indices, dtype=torch.long)\n",
        "\n"
      ],
      "metadata": {
        "id": "D-DmjrRpRIIf"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERModelRNN(nn.Module):\n",
        "    \"\"\"\n",
        "    定义用于 NER 的 RNN 神经网络模型。\n",
        "    包括嵌入层、单向 RNN 层和全连接层。\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
        "        super(NERModelRNN, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, num_tags)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        rnn_out, _ = self.rnn(embedded)\n",
        "        out = self.fc(rnn_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "RqX_sDeEQ8nt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NERModelBiLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    定义用于 NER 的神经网络模型。\n",
        "    包括嵌入层、双向 LSTM 层和全连接层。\n",
        "    \"\"\"\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_tags):\n",
        "        super(NERModelBiLSTM, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_tags)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embedded)\n",
        "        out = self.fc(lstm_out)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "dkQ_qMX6Rb0X"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置超参数\n",
        "embedding_dim = 128\n",
        "hidden_dim = 256\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 32\n",
        "\n",
        "# 读取数据\n",
        "train_sentences = read_file('ResumeNER/train.char.bmes')\n",
        "dev_sentences = read_file('ResumeNER/dev.char.bmes')\n",
        "test_sentences = read_file('ResumeNER/test.char.bmes')\n",
        "\n",
        "# 构建词汇表和标签集\n",
        "vocab, tagset = build_vocab(train_sentences)\n",
        "char2idx = {char: idx + 1 for idx, char in enumerate(vocab)}  # +1 for padding\n",
        "label2idx = {label: idx for idx, label in enumerate(tagset)}\n",
        "idx2label = {idx: label for label, idx in label2idx.items()}\n",
        "char2idx['<UNK>'] = len(char2idx)  # 添加 <UNK> 标记\n",
        "\n",
        "# 创建数据集和数据加载器\n",
        "train_dataset = NERDataset(train_sentences, char2idx, label2idx)\n",
        "dev_dataset = NERDataset(dev_sentences, char2idx, label2idx)\n",
        "test_dataset = NERDataset(test_sentences, char2idx, label2idx)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "dev_loader = DataLoader(dev_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "# 实例化模型\n",
        "model = NERModelBiLSTM(len(char2idx), embedding_dim, hidden_dim, len(tagset))\n",
        "\n",
        "# 检查是否有可用的 GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# 定义损失函数和优化器\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "4YiqeUuwRi3T",
        "outputId": "2a786bb8-9ee4-405b-b94e-d73ac8251e79"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'read_file' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-12973872efe7>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 读取数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResumeNER/train.char.bmes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdev_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResumeNER/dev.char.bmes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mtest_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ResumeNER/test.char.bmes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'read_file' is not defined"
          ]
        }
      ]
    }
  ]
}